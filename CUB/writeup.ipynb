{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " So the overall plan is something like:\n",
    "\n",
    " We want to be able to train a model, where the neuron activations have a particular signal, which guides them to activate according to a particular feature.\n",
    " There are two main ways that we can train this feature - we either give a training signal which is purely the signal\n",
    "\n",
    "Benefits of pure training:\n",
    "Confidence that the network is intending to mean what we want it to mean\n",
    "\n",
    "Benefits of mixed training:\n",
    " Allows the use of the downstream signal to disambiguate between possible generalizations of the concept that we want.\n",
    " This was the initial motivation in the ELK lens - we use the downstream training signal to push the question answerer towards the direct reporter, rather than the human simulator, because the former is more useful on the downstream tasks.\n",
    "\n",
    " This should also show up in working better with sparse labels, which we expect to be very useful since manual labels are very expensive (though automating the labelling will be necessary and might make this less useful). \n",
    "\n",
    "\n",
    " My hope was that if we trained separate Joint models, and then 'crossed the wires', so the image -> concept part of model 1 was passing its outputs to the concept -> class function of model 2 50% of the time, while 50% it still passed it to model 1, and these concept -> image model were frozen, the model would be forced to switch to a concept representation that matched to only that which the models had in common.\n",
    "\n",
    " We can see this in the clustering of the results here. Looks like there's \n",
    "\n",
    " We can show this \n",
    "\n",
    " Aside: Can we look at this through the lens of single-basin theory and see which attributes match up well to something that arises in the non-attribute loss case.?\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The idea that \n",
    "\n",
    "We started off by doing toy models in simple domains. The original push for the idea came from the idea that we would train an encoding of a layer into text and out again, rather than the text being a layer in the forward pass, as this would allow the capability of the model not to be limited by what can be expressed in language. \n",
    "\n",
    " We see this in our early experiments using autoencoders, though it would be good to be back try to demonstrate this in a feed-forward setting - I ran some basic experiments on this but it wasn't working well - this might be a serious issue but it's not the issue faced by the experiments at the moment. Hypothesis - it depends on the relative complexity of the pre and post true functions.\n",
    "\n",
    "We used a simple encoder-decoder setup to show the potential for our method to work. \n",
    "\n",
    "If you \n",
    "<div>\n",
    "<img src=\"../images/orig_sparse_img.png\", width=\"70%\" height=\"70%\"/>    \n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I moved on to getting this system working with the CUB dataset. This is a dataset which contains >10K images of birds, which are each labelled as being one of 200 species of bird. They are also given binary labels for 312 features which describe the birds' appearances. These categories are divided into 28 categories, such as beak-shape, and only one of these categories are true for any image.\n",
    "\n",
    "Although one would expect that the actual characteristics of the bird are the same for each bird, the labels differ significantly between birds, and labels are also often marked not-visible. As a result of this, most papers which use the CUB dataset make the task  easier by reducing the number of categories to those which are true in at least 10 cases, which is around 110 (109 in my own experiments, 112 in the original). They also make it much easier by doing a majority-voting transform, by which the labels for each image are replaced by the most common category forbirds of that species, within the test set.\n",
    "\n",
    "This second transform not only makes the task much easier but changes the entire concept of building a concept model - because to predict the way to predict the features is in fact to predict the class and then use this to deterministically predict all of the features. It is unsurprising that the models which do this perform well, but it is not the task that we are interested in, so I stopped using this transform. This also has the benefit that, being a much harder task, there's a big gap between the performance of a sequential model (about 50% top-1 on test set) and of the joint models, (about 70% top-1 on the test set), and in the opposite direction on the performance with full intervention - only about 18% with joint, 30%  with sequential, and 50% on independent models. This gives us a clear space beyond the Pareto frontier of performance to aim into with our improved systems."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main thing we want to see is what happens when we take two models which have been trained separately, and train them such that we've crossed the wires.\n",
    "\n",
    "We have two main metrics - the performance on the test set, and the performance on the test set when the estimated concepts have been fully replaced by the true values - this second test is the best evidence we have of the fidelity of the concept model.\n",
    "\n",
    "I trained a series of joint models to the point at which their validation loss plateaus, and then merged them into a joint model, which trains them for 20 epochs separately, and then 50 epochs while shuffling the wires, while freezing the premodels, so that the concept outputs don't change after epoch 20. The results are shown below.\n",
    "\n",
    "What we see is that the train performance, which continues to rise until the 20th epoch, drops slightly and plateaus (but only drops a little) and the validation performance stays entirely the same! Instead of the spike in loss that I hoped and expected to see, the rise in loss is minimal and the level of performance is pretty consistent, especially on the validation set.\n",
    "\n",
    "<div>\n",
    "<img src=\"../images/joint2multi_loss.png\", width=\"40%\">\n",
    "<img src=\"../images/joint2multi_acc.png\", width=\"40%\", class=\"right\">\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this hypothesis further, I train two multimodels without ever shuffling, and continuously keep track of the accuracy of classification when the outputs of the first concept model are fed into the classifier in the second model.\n",
    "\n",
    "We get the following graph:\n",
    "<div>\n",
    "<img src=\"../images/demonstrating_shared_info.png\", width=30%>\n",
    "</div>\n",
    "\n",
    "What we can see is that the cross-accuracy is high, only a small amount below the train accuracy. Crucially, it's far above the level of accuracy that is achieved by using a sequential model, let alone an independent model.\n",
    "\n",
    "The hypothesis was that this additional information would not have a natural basis in the concept layer, and so would be encoded in roughly orthogonal ways between the two models. If this were true then we would expect the cross accuracy to be far lower than the train accuracy, perhaps as low the sequential model, if the C -> Y model was only able to pick up on the concept information, and perhaps worse if it were *misinterpreting* the additional information.\n",
    "\n",
    "There is a way in which this could be explained by the joint models having better understanding of the concepts thanks to the end-to-end signal that the concept model lacks, helping it to find useful generalizations of the concept labels. However, if this were the case then we would expect to see the joint models performing well under full intervention, whereas what we actually see is very poor performance when the output oof the models is replaced with the true concept labels, suggesting that it is actually hidden information that is being encoded in similar ways between the two models, and not just better concepts models.\n",
    "\n",
    "This is interesting as it doesn't\n",
    "TEST: What happens if you run with `attr_loss = 0` and then test performance on the attr tasks, when finding the best possible permutation of the attrs? \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This to me seems like a point of evidence in favour of the idea that there's roughly a single basin of attraction, along the lines suggested in the [Git Re-Basin paper](https://arxiv.org/pdf/2209.04836.pdf) - that there's a particular set of features that are likely to emerge at a particular layer, and the primary source of uncertainty is just which feature will be matched to which neuron, and th\n",
    "\n",
    "The interpretation that I take from this is that there's a natural set of concepts that arise given the concept\n",
    "\n",
    "It's interesting to think how this would play out in networks which display polysemanticity - \n",
    "\n",
    "Does it depend on the strength of the concept loss? It seems that if we train a model with no concept loss then would we get not only different features at different neurons - we could test this by having different strengths of loss on the different models, and look at how this changes the set of featuers that arises."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see similar effects for a sequential model, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b95b6b691c30533c324664bd6a9848f5f6465bdf018a5870117d4007cfdc865"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
