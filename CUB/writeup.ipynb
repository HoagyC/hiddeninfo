{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " So the overall plan is something like:\n",
    "\n",
    " We want to be able to train a model, where the neuron activations have a particular signal, which guides them to activate according to a particular feature.\n",
    " There are two main ways that we can train this feature - 'Sequential' or 'Joint'. In Sequential we train the two parts of the network - before and after the concept layer - separately. We first use the \n",
    "\n",
    "Benefits of pure training:\n",
    "Confidence that the network is intending to mean what we want it to mean\n",
    "\n",
    "Benefits of mixed training:\n",
    " Allows the use of the downstream signal to disambiguate between possible generalizations of the concept that we want.\n",
    " This was the initial motivation in the ELK lens - we use the downstream training signal to push the question answerer towards the direct reporter, rather than the human simulator, because the former is more useful on the downstream tasks.\n",
    "\n",
    " This should also show up in working better with sparse labels, which we expect to be very useful since manual labels are very expensive (though automating the labelling will be necessary and might make this less useful). \n",
    "\n",
    "\n",
    " My hope was that if we trained separate Joint models, and then 'crossed the wires', so the image -> concept part of model 1 was passing its outputs to the concept -> class function of model 2 50% of the time, while 50% it still passed it to model 1, and these concept -> image model were frozen, the model would be forced to switch to a concept representation that matched to only that which the models had in common.\n",
    "\n",
    " We can see this in the clustering of the results here. Looks like there's \n",
    "\n",
    " We can show this \n",
    "\n",
    " Aside: Can we look at this through the lens of single-basin theory and see which attributes match up well to something that arises in the non-attribute loss case.?\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The idea that \n",
    "\n",
    "We started off by doing toy models in simple domains. The original push for the idea came from the idea that we would train an encoding of a layer into text and out again, rather than the text being a layer in the forward pass, as this would allow the capability of the model not to be limited by what can be expressed in language. \n",
    "\n",
    " We see this in our early experiments using autoencoders, though it would be good to be back try to demonstrate this in a feed-forward setting - I ran some basic experiments on this but it wasn't working well - this might be a serious issue but it's not the issue faced by the experiments at the moment. Hypothesis - it depends on the relative complexity of the pre and post true functions.\n",
    "\n",
    "We used a simple encoder-decoder setup to show the potential for our method to work. \n",
    "\n",
    "If you "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div>\n",
    "<img src=\"../images/orig_sparse_img.png\", width=\"50%\" height=\"70%\"/>    \n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I moved on to getting this system working with the CUB dataset. This is a dataset which contains >10K images of birds, which are each labelled as being one of 200 species of bird. They are also given binary labels for 312 features which describe the birds' appearances. These categories are divided into 28 categories, such as beak-shape, and only one of these categories are true for any image.\n",
    "\n",
    "Although one would expect that the actual characteristics of the bird are the same for each bird, the labels differ significantly between birds, and labels are also often marked not-visible. As a result of this, most papers which use the CUB dataset make the task  easier by reducing the number of categories to those which are true in at least 10 cases, which is around 110 (109 in my own experiments, 112 in the original). They also make it much easier by doing a majority-voting transform, by which the labels for each image are replaced by the most common category forbirds of that species, within the test set.\n",
    "\n",
    "This second transform not only makes the task much easier but changes the entire concept of building a concept model - because to predict the way to predict the features is in fact to predict the class and then use this to deterministically predict all of the features. It is unsurprising that the models which do this perform well, but it is not the task that we are interested in, so I stopped using this transform. This also has the benefit that, being a much harder task, there's a big gap between the performance of a sequential model (about 50% top-1 on test set) and of the joint models, (about 70% top-1 on the test set), and in the opposite direction on the performance with full intervention - only about 18% with joint, 30%  with sequential, and 50% on independent models. This gives us a clear space beyond the Pareto frontier of performance to aim into with our improved systems."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main thing we want to see is what happens when we take two models which have been trained separately, and train them such that we've 'crossed the wires' - 50% of the time putting the concept vectors predicted by one model into the second model as vice versa - how well will the classifiers work on concept vectors generated by a different model to the one that they are used to.\n",
    "\n",
    "We have two main metrics - the performance on the test set, and the performance on the test set when the estimated concepts have been fully replaced by the true values - this second test is the best evidence we have of the fidelity of the concept model.\n",
    "\n",
    "I trained a pair of joint models to the point at which their validation loss plateaus (this training not shown), and then merged them into a multimodel, which trains them for 20 epochs separately, and then 50 epochs while shuffling the wires. In this second phase of training, I froze the premodels, so that the concept outputs don't change after epoch 20 and the class classifier has to work with inputs that could be from either concept model.\n",
    "\n",
    "What we see is that the train performance, which continues to rise until the 20th epoch, drops slightly and plateaus (but only drops a little) and the validation performance stays entirely the same! Instead of the spike in loss that I hoped and expected to see, the rise in loss is minimal and the level of performance is pretty consistent, especially on the validation set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div>\n",
    "<img src=\"../images/joint2multi_loss.png\", width=\"20%\">\n",
    "<img src=\"../images/joint2multi_acc.png\", width=\"20%\", class=\"right\">\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better idea of what's going on, I trained two multimodels without ever shuffling, and continuously kept track of the accuracy of classification when the outputs of the first concept model are fed into the classifier in the second model.\n",
    "\n",
    "We get the following graph:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div>\n",
    "<img src=\"../images/demonstrating_shared_info.png\", width=20%>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "What we can see is that the cross-accuracy on the train set is high - only a small amount below the train accuracy. Crucially, it's far above the level of accuracy that is achieved by using a sequential model, let alone an independent model.\n",
    "\n",
    "The hypothesis underlying the Distilled Representations agenda was that this additional information would not have a natural basis in the concept layer, and so would be encoded in roughly orthogonal ways between the two models. If this were true then we would expect the cross accuracy to be far lower than the train accuracy, perhaps as low the sequential model, if the C -> Y model was only able to pick up on the concept information, and perhaps worse if it were *misinterpreting* the additional information.\n",
    "\n",
    "There is a way in which this could be explained without violating the assumptions for distilled representations. If the joint models had better understanding of the concepts thanks to the end-to-end signal that the concept model lacks, and so they were both learning the same variations on the concepts, this wouldn't be a case of hidden information represented in the same way. However, if this were the case then we would expect to see the joint models performing well under full intervention, whereas what we actually see is very poor performance when the output of the models is replaced with the true concept labels, suggesting that it is actually hidden information that is being encoded in similar ways between the two models, and not just better concepts models. Below, we can see that when the predicted concepts are fully replaced with their labels (red line), performance drops to only about 15% top-1, below what s is seen with sequential models, showing that they aren't just learning better concept generalizations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"../images/tti_when_shuffle.png\", width=20%>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see similar effects for a sequential model - here we can see that the sequential model learns slower  and that even when switching between models that have been trained totally separately, the switched performance far exceeds the performance of the sequential model for both training and validation sets. (If trained for longer, sequential models eventually plateau at around 50% top-1 val accuracy and 40% train accuracy - the train task is actually significantly harder due to dropout, which I keep in here to make the task analogous to the joint training case.) This is clear evidence that there is a natural way for the models to learn the additional information that allows for high performance. The epochs begin at 150 because the first 150 epochs were used to train the image to concept model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"../images/wandb_concat.png\", width=20%>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This to me seems like a point of evidence in favour of the idea that there's roughly a single basin of attraction, along the lines suggested in the [Git Re-Basin paper](https://arxiv.org/pdf/2209.04836.pdf) - that there's a particular set of features that are likely to emerge at a particular layer, and the primary source of uncertainty is just which feature will be matched to which neuron. This is an instance of universality as first suggested in Li et al's [Convergent Learning (2016)](https://arxiv.org/pdf/1511.07543.pdf)\n",
    "\n",
    "What we seem to see here is both that there's a natural way to encode the additional information that moves performance from the level of sequential models to the level of joint models, and that given. This makes sense under the univsersality hypothesis - if we assumed that there's a particular set of additional features that help with downstream performance, it's quite natural that there's a privileged way to integrate this extra information with the need to minimize the concept loss."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests a number of potential tests:\n",
    "\n",
    "TEST: Do we still get transferrable performance if we modify the architecture in various ways?\n",
    "\n",
    "TEST: Do we still get transferrable performance if we vary the `attr_loss` coefficient?\n",
    "\n",
    "TEST: Can we use the matching methods described in GitRebasin to predict the concepts that are learned by sequential / joint models?\n",
    "\n",
    "Interaction with polysemanticity? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b95b6b691c30533c324664bd6a9848f5f6465bdf018a5870117d4007cfdc865"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
